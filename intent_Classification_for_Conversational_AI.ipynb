{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahnavikolli/Intent-Classification-for-Conversational-AI-Systems/blob/main/intent_Classification_for_Conversational_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAlu160VtgeG",
        "outputId": "c135104d-079e-4875-ac11-38d08ad11eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         sentence label\n",
            "0                    You guys provide EMI option?   EMI\n",
            "1  Do you offer Zero Percent EMI payment options?   EMI\n",
            "2                                         0% EMI.   EMI\n",
            "3                                             EMI   EMI\n",
            "4                           I want in installment   EMI\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sheet_id = \"1BG4GYGscyd4inQ2RuZUunzhxil2q0OklbktNRCOuNLg\"\n",
        "sheet_name = \"sofmattress_train\"\n",
        "\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr8d7dPdtYHN"
      },
      "outputs": [],
      "source": [
        "sentences = df['sentence'].astype(str).values\n",
        "labels = df['label'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VkPMLxPttvU"
      },
      "source": [
        "# Preprocessing( Cleaning and Label Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUfiLpIlQs-v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDJa9rqTGwX"
      },
      "source": [
        "Extracting sentences and cleaning the sentences using NLTK library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B3u5uwfSQH4",
        "outputId": "94e217f8-0cf2-4bf8-8d04-a21f612397c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Downloading stopwords (Ex: The, and, is etc.,)\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)  # Remove stopwords\n",
        "    text = text.strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# cleaning the sentences column\n",
        "df[\"cleaned_sentence\"] = df[\"sentence\"].apply(clean_text)\n",
        "sentences = df[\"cleaned_sentence\"].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJFzEO6E3Fmy"
      },
      "outputs": [],
      "source": [
        "# Extracting labels\n",
        "labels = df[\"label\"].values\n",
        "\n",
        "# Encode the labels to numbers\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)  # Converts labels to integers\n",
        "\n",
        "# One-hot encode labels (for LSTM)\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique labels\n",
        "one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d_2aSSz3RT3"
      },
      "source": [
        "# Tokenization and Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCK3Zlqo3Q-J"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")  # To handle unseen words\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
        "\n",
        "# Converting text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Padding sequences to ensure all the sentences are of same length.\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "# Setting the padding to max_length of all the sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW0BpHmXEC79",
        "outputId": "8ec3a379-2fca-4539-9883-8bf56cc8970e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'mattress': 2, 'order': 3, 'want': 4, 'sof': 5, 'size': 6, 'available': 7, 'need': 8, 'emi': 9, 'cost': 10, 'ergo': 11, 'trial': 12, 'get': 13, 'buy': 14, 'back': 15, 'price': 16, 'features': 17, 'ortho': 18, 'product': 19, 'warranty': 20, 'status': 21, 'cod': 22, 'know': 23, 'pillows': 24, 'offer': 25, 'pincode': 26, 'delivery': 27, 'tell': 28, 'products': 29, 'cancel': 30, 'option': 31, 'night': 32, 'return': 33, 'call': 34, 'paisa': 35, 'deliver': 36, 'variants': 37, 'offers': 38, 'help': 39, 'please': 40, 'store': 41, 'finance': 42, 'custom': 43, 'days': 44, 'sizes': 45, 'showroom': 46, 'shop': 47, 'pain': 48, 'difference': 49, 'exchange': 50, 'inches': 51, 'show': 52, 'touch': 53, 'x': 54, 'payment': 55, 'possible': 56, 'problem': 57, 'looking': 58, 'mattresses': 59, 'comparison': 60, 'details': 61, 'check': 62, 'chart': 63, 'agent': 64, 'state': 65, 'nearby': 66, 'different': 67, 'month': 68, 'discount': 69, 'provide': 70, 'options': 71, 'installments': 72, 'cash': 73, 'key': 74, 'issue': 75, 'foam': 76, 'compare': 77, 'cover': 78, 'long': 79, 'share': 80, 'interested': 81, 'customisation': 82, 'free': 83, 'nights': 84, 'give': 85, 'change': 86, 'customise': 87, 'bed': 88, 'live': 89, 'distributors': 90, 'city': 91, 'ft': 92, 'visit': 93, 'offline': 94, 'stores': 95, 'shops': 96, 'dealership': 97, 'near': 98, 'much': 99, 'best': 100, 'type': 101, 'many': 102, 'delayed': 103, 'delivered': 104, 'refund': 105, 'process': 106, 'guys': 107, 'zero': 108, 'percent': 109, 'installment': 110, 'interest': 111, 'payments': 112, 'service': 113, 'minimum': 114, 'accept': 115, 'card': 116, 'availble': 117, 'acceptable': 118, 'pay': 119, 'later': 120, 'orthopaedic': 121, 'neck': 122, 'ache': 123, 'slip': 124, 'disc': 125, 'anything': 126, 'backache': 127, 'cervical': 128, 'lombard': 129, 'section': 130, 'orthopedic': 131, 'responsive': 132, 'ergonomic': 133, 'support': 134, 'good': 135, 'wanna': 136, 'period': 137, 'included': 138, 'information': 139, 'would': 140, 'work': 141, 'enroll': 142, 'applicable': 143, 'well': 144, 'try': 145, 'first': 146, 'version': 147, 'changing': 148, 'sized': 149, 'customised': 150, 'length': 151, 'feet': 152, 'structure': 153, 'king': 154, 'talk': 155, 'schedule': 156, 'callback': 157, 'arrange': 158, 'buying': 159, 'connect': 160, 'representative': 161, 'able': 162, 'make': 163, 'pin': 164, 'code': 165, 'showrooms': 166, 'delhi': 167, 'mumbai': 168, 'retailers': 169, 'pune': 170, 'see': 171, 'distributorsretailersshowrooms': 172, 'room': 173, 'nearest': 174, 'demo': 175, 'head': 176, 'office': 177, 'branch': 178, 'dealer': 179, 'ship': 180, 'outlet': 181, 'range': 182, 'rate': 183, 'mrp': 184, 'low': 185, 'view': 186, 'used': 187, 'brands': 188, 'company': 189, 'receive': 190, 'yet': 191, 'almost': 192, 'havent': 193, 'received': 194, 'already': 195, 'one': 196, 'late': 197, 'related': 198, 'number': 199, 'track': 200, 'updates': 201, 'present': 202, 'current': 203, 'expect': 204, 'money': 205, 'happy': 206, 'replace': 207, 'replacement': 208, 'policy': 209, 'cancellation': 210, 'cancelling': 211, 'sell': 212, 'pair': 213, 'cushions': 214, 'also': 215, 'discounts': 216, 'may': 217, 'latest': 218}\n",
            "Vocabulary size: 219\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.word_index)  # word-to-index mapping\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdsQqxmLEXd0",
        "outputId": "a69e4db7-09c1-42bc-8bd0-233d97f67502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[107  70   9  31   0   0   0   0   0   0   0   0]\n",
            " [ 25 108 109   9  55  71   0   0   0   0   0   0]\n",
            " [  9   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  9   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4 110   0   0   0   0   0   0   0   0   0   0]]\n",
            "Padded shape: (328, 12)\n"
          ]
        }
      ],
      "source": [
        "print(padded_sequences[:5])  # Printing first 5 padded sequences to check if they are all of same length\n",
        "print(f\"Padded shape: {padded_sequences.shape}\")  # Total number of sequences, max_length\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okAc7Iyz3XVG"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peWu9cC13VEN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sequences, one_hot_labels, test_size=0.2, random_state=42, stratify=one_hot_labels\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbLyO7VeJz2t",
        "outputId": "82ffe576-8cde-442a-c8bd-81651cfa72a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (262, 12)\n",
            "y_train shape: (262, 21)\n",
            "X_test shape: (66, 12)\n",
            "y_test shape: (66, 21)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbosg3oFK5X2"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvtwB4b5xhRL",
        "outputId": "883f3121-5774-41a7-e253-a5443b1298b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-20 17:42:57--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-02-20 17:42:57--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-02-20 17:42:57--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.59MB/s    in 2m 39s  \n",
            "\n",
            "2025-02-20 17:45:36 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "# Downloading the GloVe model\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZdKOsbLw0yG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Loading GloVe embedding model\n",
        "embedding_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]  # Word\n",
        "        coefs = np.asarray(values[1:], dtype=\"float32\")  # Embedding values\n",
        "        embedding_index[word] = coefs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYgFvtqvw4em"
      },
      "outputs": [],
      "source": [
        "# Creating embedding matrix\n",
        "embed_dim = 100  # Size of GloVe vectors ( Loaded a 100d model, embed_dim and model dim should match)\n",
        "embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BXmA7HwChoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f1748b-07be-4145-f766-49915f3918fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(219, 100)\n"
          ]
        }
      ],
      "source": [
        "print(embedding_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwz6tOXI4UM7"
      },
      "source": [
        "# Building LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCnlgCLQG4rB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "49ebcc52-cdfa-49fa-e84d-b19b51d657d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m21,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m84,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │           \u001b[38;5;34m1,365\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,365</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,001\u001b[0m (453.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,001</span> (453.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m94,101\u001b[0m (367.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,101</span> (367.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,900\u001b[0m (85.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,900</span> (85.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
        "\n",
        "# Input length same as my padded sequences\n",
        "input_length = 12\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    Input(shape=(input_length,)),  # Input layer\n",
        "    Embedding(input_dim=vocab_size, output_dim=100, input_length=input_length,\n",
        "              weights=[embedding_matrix], trainable=False),\n",
        "    Bidirectional(LSTM(64, dropout=0.1, return_sequences=False)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model summary to check if the model is building well or not\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd1VgCR0F9uH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf6ae8d-b9b1-4cd3-bd02-9788304eaa1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(328,)\n",
            "<class 'numpy.ndarray'>\n",
            "['EMI' 'EMI' 'EMI' 'EMI' 'EMI']\n"
          ]
        }
      ],
      "source": [
        "print(labels.shape)\n",
        "print(type(labels))\n",
        "print(labels[:5])  # Preview first 5 labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fH6JGbevPZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c918bf-fc6d-445c-ada8-b8dcd61816b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.0640 - loss: 3.0306 - val_accuracy: 0.2727 - val_loss: 2.9336\n",
            "Epoch 2/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2358 - loss: 2.9129 - val_accuracy: 0.4394 - val_loss: 2.7842\n",
            "Epoch 3/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3650 - loss: 2.6852 - val_accuracy: 0.4091 - val_loss: 2.4209\n",
            "Epoch 4/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4009 - loss: 2.2508 - val_accuracy: 0.4394 - val_loss: 2.0510\n",
            "Epoch 5/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4837 - loss: 1.8750 - val_accuracy: 0.5152 - val_loss: 1.7623\n",
            "Epoch 6/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5917 - loss: 1.6026 - val_accuracy: 0.6212 - val_loss: 1.5044\n",
            "Epoch 7/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6478 - loss: 1.4006 - val_accuracy: 0.7121 - val_loss: 1.2824\n",
            "Epoch 8/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6908 - loss: 1.1843 - val_accuracy: 0.6970 - val_loss: 1.1669\n",
            "Epoch 9/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7061 - loss: 1.1414 - val_accuracy: 0.7576 - val_loss: 1.0495\n",
            "Epoch 10/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7533 - loss: 0.9488 - val_accuracy: 0.7576 - val_loss: 0.9169\n",
            "Epoch 11/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7610 - loss: 0.8336 - val_accuracy: 0.7424 - val_loss: 0.9517\n",
            "Epoch 12/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8106 - loss: 0.7201 - val_accuracy: 0.7879 - val_loss: 0.8984\n",
            "Epoch 13/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8634 - loss: 0.6061 - val_accuracy: 0.7424 - val_loss: 0.8602\n",
            "Epoch 14/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8312 - loss: 0.6004 - val_accuracy: 0.7576 - val_loss: 0.8548\n",
            "Epoch 15/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8938 - loss: 0.4798 - val_accuracy: 0.7879 - val_loss: 0.8393\n"
          ]
        }
      ],
      "source": [
        "training = model.fit(X_train, y_train, epochs=15, batch_size=16, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6KNoqetvYTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870567cf-e208-4720-9541-456429b7916a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7846 - loss: 0.8036\n",
            "Test Accuracy: 0.79\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8klHpEjnZrfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f479924a-59f2-4c34-fbae-790cfdd6bcd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.75      0.75         4\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       1.00      0.50      0.67         2\n",
            "           5       1.00      0.50      0.67         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       1.00      0.86      0.92         7\n",
            "           8       0.83      1.00      0.91         5\n",
            "           9       1.00      0.50      0.67         2\n",
            "          10       1.00      0.75      0.86         4\n",
            "          11       1.00      0.80      0.89         5\n",
            "          12       1.00      1.00      1.00         2\n",
            "          13       0.75      0.75      0.75         4\n",
            "          14       0.80      1.00      0.89         4\n",
            "          15       1.00      1.00      1.00         2\n",
            "          16       0.50      0.75      0.60         4\n",
            "          17       0.50      0.67      0.57         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       1.00      1.00      1.00         2\n",
            "          20       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.79        66\n",
            "   macro avg       0.81      0.77      0.77        66\n",
            "weighted avg       0.82      0.79      0.79        66\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
        "y_true_classes = y_test.argmax(axis=1)  # Convert one-hot encoded labels to class labels\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPkIQ1XhC9zK"
      },
      "source": [
        "Checking for any unpredicted classes\n",
        "* If both the y_pred and y_test_classes are equal then there are no unpredicted classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLgOowvScHus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e723f249-61df-4e01-9b82-5e88ad4918aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert the one-hot encoded values to class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzyLv6M3cWE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db98705-5e84-4969-93bf-06990f1542ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "21\n"
          ]
        }
      ],
      "source": [
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "print(len(np.unique(y_pred)))\n",
        "print(len(np.unique(y_test_classes)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBNxlX2VwhOGwfOCc8y51+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}